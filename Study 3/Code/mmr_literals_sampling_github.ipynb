{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dfa665-8d73-4a21-acfe-7b267287a831",
   "metadata": {},
   "source": [
    "### Maximal Marginal Relevance (MMR)\n",
    "Select k samples that are as different from each other as possible (based on cosine distance of embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bee01a-25fc-40f5-b544-c6ff38c135f7",
   "metadata": {},
   "source": [
    "### Version with a threshold - only add values that are dissimilar enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b58411-c335-400e-8509-677ad1d7fdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.org/src#samplingtime: ['12:49:00']\n",
      "http://example.org/src#patient_cpr: ['te64687489', 'c0cef4fadfd', 'dc44b505e4e', 'afedd9d7f0', 'cdse4751d0']\n",
      "http://example.org/src#analysiscode: ['DNK35312', 'NPU02070']\n",
      "http://example.org/src#laboratorium_idcode: ['UKN', 'OUI', 'ESB', 'HDI', 'KPL']\n",
      "http://example.org/src#referenceinterval_lowerlimit: ['50.0', '137.0', '27.0']\n",
      "http://example.org/src#referenceinterval_upperlimit: ['30.0', '7.5', '105.0']\n",
      "http://example.org/src#unit: ['U/L', 'mL/min', '10^6/l', 'mg/g', 'mol/l']\n",
      "http://example.org/src#rekvirent_idtype: ['sorkode', 'sygehusafdelingsnummer', 'yaugethusgbdnummer', 'ydernummer']\n",
      "http://example.org/src#samplingdate: ['2010-12-07', '2017-04-16', '2023-10-27']\n",
      "http://example.org/src#resulttype: ['alfanumerisk', 'numerisk']\n",
      "http://example.org/src#value: ['00', 'A RhD pos', '>175', 'NEG', '137']\n",
      "http://example.org/src#operator: ['stoerre_end', 'mindre_end']\n",
      "http://example.org/src#resultvalidation: ['for_hoej']\n",
      "http://example.org/src#rekvirent_id: ['0123815', '1789AFS4611', '2000A005', '6620378SKADE', '990202']\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Literal\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load RDF graph\n",
    "graph = Graph()\n",
    "graph.parse(\"src_data_graph_new.nt\", format=\"nt\")\n",
    "\n",
    "# Extract literal values per datatype property\n",
    "property_literals = defaultdict(set)\n",
    "for s, p, o in graph:\n",
    "    if isinstance(o, Literal):\n",
    "        property_literals[str(p)].add(str(o))\n",
    "\n",
    "# MMR (Maximal Marginal Relevance) with threshold\n",
    "def mmr_thresholded(embeddings, texts, k=5, diversity=0.7, similarity_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Perform Maximal Marginal Relevance (MMR) sampling with a similarity threshold.\n",
    "\n",
    "    This function selects a subset of `k` text values from a list using the MMR algorithm.\n",
    "    MMR balances two criteria:\n",
    "      - relevance (how representative a value is),\n",
    "      - and diversity (how different a value is from those already selected).\n",
    "\n",
    "    A candidate will only be added to the result if it is sufficiently dissimilar to the\n",
    "    already selected items â€” determined by a maximum pairwise cosine similarity threshold.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    embeddings : np.ndarray\n",
    "        A 2D numpy array of shape (n_samples, n_dimensions) containing the vector\n",
    "        representations (e.g., from Sentence-BERT) of the input texts.\n",
    "\n",
    "    texts : List[str]\n",
    "        The original list of text strings corresponding to the embeddings. Must be the same\n",
    "        length as `embeddings`.\n",
    "\n",
    "    k : int, optional (default=5)\n",
    "        The maximum number of values to select.\n",
    "\n",
    "    diversity : float, optional (default=0.7)\n",
    "        A weight between 0 and 1. Higher values increase the importance of dissimilarity;\n",
    "        lower values favor relevance (centrality). Typically between 0.5 and 0.9.\n",
    "\n",
    "    similarity_threshold : float, optional (default=0.85)\n",
    "        The maximum allowed cosine similarity (range: 0 to 1) between a candidate and any\n",
    "        already selected item. If the most similar match exceeds this threshold, the candidate\n",
    "        is rejected. Lower values lead to higher diversity in the final selection.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[str]\n",
    "        A list of selected texts, up to `k` in length, satisfying both MMR and the similarity\n",
    "        constraint. May return fewer than `k` items if diversity constraints prevent more being added.\n",
    "    \"\"\"\n",
    "    if len(texts) <= k:\n",
    "        return texts\n",
    "\n",
    "    selected = [0]\n",
    "    candidates = list(range(1, len(embeddings)))\n",
    "\n",
    "    while len(selected) < k and candidates:\n",
    "        mmr_scores = []\n",
    "        for i in candidates:\n",
    "            sim_to_selected = max(cosine_similarity([embeddings[i]], [embeddings[j] for j in selected])[0])\n",
    "            relevance = np.mean(embeddings[i])\n",
    "            mmr_score = diversity * relevance - (1 - diversity) * sim_to_selected\n",
    "            mmr_scores.append((i, mmr_score, sim_to_selected))\n",
    "\n",
    "        mmr_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        added = False\n",
    "        for idx, score, max_sim in mmr_scores:\n",
    "            if max_sim < similarity_threshold:\n",
    "                selected.append(idx)\n",
    "                candidates.remove(idx)\n",
    "                added = True\n",
    "                break\n",
    "\n",
    "        if not added:\n",
    "            break\n",
    "\n",
    "    return [texts[i] for i in selected]\n",
    "\n",
    "# Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sampled results\n",
    "final_samples = {}\n",
    "target_k = 5\n",
    "\n",
    "# Loop over each property\n",
    "for prop, values in property_literals.items():\n",
    "    values = list(values)\n",
    "    if len(values) == 0:\n",
    "        continue\n",
    "\n",
    "    prepped_values = [f\"val: {v}\" for v in values]\n",
    "    embeddings = np.array(model.encode(prepped_values))\n",
    "\n",
    "    # K-means clustering (optional, for initial variety)\n",
    "    n_clusters = min(target_k * 2, len(values))  # more clusters to increase diversity\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(embeddings)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # One value per cluster\n",
    "    seen_clusters = set()\n",
    "    clustered_vals = []\n",
    "    clustered_embeds = []\n",
    "\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        if label not in seen_clusters:\n",
    "            seen_clusters.add(label)\n",
    "            clustered_vals.append(values[i])  # un-prefixed value\n",
    "            clustered_embeds.append(embeddings[i])\n",
    "\n",
    "    # Apply MMR with threshold\n",
    "    mmr_selected = mmr_thresholded(\n",
    "        embeddings=np.array(clustered_embeds),\n",
    "        texts=clustered_vals,\n",
    "        k=target_k,\n",
    "        diversity=0.7,\n",
    "        similarity_threshold=0.85\n",
    "    )\n",
    "\n",
    "    final_samples[prop] = mmr_selected\n",
    "\n",
    "# Show output\n",
    "for prop, sample in final_samples.items():\n",
    "    print(f\"{prop}: {sample}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama_env)",
   "language": "python",
   "name": "llama_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
